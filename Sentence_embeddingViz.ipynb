{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd25c6c-2da0-4124-8b90-34bc2c935042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.12.2 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n",
      "C:\\ProgramData\\miniconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from torch import nn as nn\n",
    "\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tqdm\n",
    "from torcheval.metrics.functional import multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93518832-8ec5-4283-816e-cc036f23e238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b711f7-af52-4587-b6f4-f7190847d582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_data(language, data_dir):\n",
    "    data_files = {\"train\": data_dir + language+'/train.tsv', \n",
    "                  \"dev\": data_dir + language+'/dev.tsv',\n",
    "                  \"test\": data_dir + language+'/test.tsv' }\n",
    "    \n",
    "    language_data = load_dataset(\"csv\", data_files=data_files, sep=\"\\t\")\n",
    "    return language_data   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1702d482-6764-4d3f-be91-dbe785391ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingExtractor(nn.Module):\n",
    "    def __init__(self, model_string):\n",
    "        super().__init__()\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_string)\n",
    "        self._model = AutoModelForSequenceClassification.from_pretrained(model_string, num_labels= 3,  output_hidden_states=True)\n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def embedding_idex(self):\n",
    "        return self._embedding_index   \n",
    "        \n",
    "    def forward(self, inputs, index, with_prediction =False):\n",
    "        output= self._model(**inputs)        \n",
    "        embedding = output['hidden_states'][index]  \n",
    "        attention_mask = inputs['attention_mask'] # return output\n",
    "        embedding_pooled = self.mean_pooling(embedding, attention_mask) \n",
    "        if with_prediction:            \n",
    "            scores = nn.functional.softmax(output['logits'], dim=1)\n",
    "            predictions = torch.argmax(scores, dim=1)\n",
    "            return  embedding_pooled, inputs['labels'], predictions\n",
    "        return  embedding_pooled, inputs['labels']\n",
    "    def mean_pooling(self, model_output, attention_mask):        \n",
    "        token_embeddings = model_output #First element of model_output contains all token embeddings        \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()        \n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fb6b1b-bb5e-45f5-afd1-8aabbb819589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a722e6b4-bb7e-440b-8d69-1097d12ff8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5640d100eef47648c85c7e5be75efd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_string', options={'AfriBerta': 'Davlan/naija-twitter-sentimeâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(model_string={\"AfriBerta\":\"Davlan/naija-twitter-sentiment-afriberta-large\"\n",
    "                        , \"Bert-base\":\"bert-base-multilingual-cased\"}\n",
    "          , lang ={\"Ibo\": 'ibo', \"Yoruba\": 'yor', \"Pidgen\":'pcm', \"Hausa\": 'hau'}\n",
    "          , data_dir='naija_sent_data/annotated_tweets/', batch = range(10, 101, 10), index=[-1,0]\n",
    "          , max_retrieved = range(50, 501, 50))\n",
    "def visualize_embeddings(model_string, lang, data_dir, batch, index, max_retrieved):    \n",
    "# def visualize_embeddings(model_params, lang, data_dir, id2label, label2id, batch):   \n",
    "    id2label ={0:\"positive\", 1:\"neutral\", 2:\"negative\"}\n",
    "    label2id = {\"positive\": 0, \"neutral\": 1, \"negative\": 2}\n",
    "    \n",
    "    ################\n",
    "    def collate_fn (batch):\n",
    "        features  = [{\"input_ids\": d['input_ids'], \"attention_mask\":  d['attention_mask'], \"label\":  d['label']} for d in batch]\n",
    "        c = data_collator(features)\n",
    "        return c\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        tokenized_batch = tokenizer(examples['tweet'], truncation=True, padding= True)\n",
    "        tokenized_batch[\"label\"] = [label2id[label] for label in examples[\"label\"]]\n",
    "        return tokenized_batch\n",
    "\n",
    "    # instantiate model initializer\n",
    "    print(\"Analyzes for  \"+lang)    \n",
    "    extractor = EmbeddingExtractor(model_string)\n",
    "    tokenizer = extractor.tokenizer\n",
    "    # # summary(extractor.model, input_size = (768,), depth=1, batch_dim =1, dtypes=['torch.IntTensor'])\n",
    "    # # return\n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer) \n",
    "    \n",
    "    ## retrieve data    \n",
    "    language_data = retrieve_data(lang, data_dir)   \n",
    "    tokenized_data = language_data.map(preprocess_function, batched=True)    \n",
    "    ###########################\n",
    "    train_loader = DataLoader(tokenized_data['train'], batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(tokenized_data['dev'], batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(tokenized_data['test'], batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    retrieved_embeddings = None  \n",
    "    retrieved_labels = None\n",
    "    predicted_labels= None\n",
    "    sentences = []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(train_loader): \n",
    "            for encoded in data['input_ids']:\n",
    "                sentences.append(tokenizer.decode(encoded, skip_special_tokens=True))            \n",
    "            embedding, labels, predictions = extractor(data, index, with_prediction= True)\n",
    "            embedding, labels, predictions = embedding.detach(), labels.detach(), predictions.detach()\n",
    "            if not isinstance(retrieved_embeddings, torch.Tensor):\n",
    "                retrieved_embeddings = embedding\n",
    "                retrieved_labels = labels\n",
    "                predicted_labels = predictions\n",
    "            else:   \n",
    "                retrieved_embeddings = torch.cat((retrieved_embeddings, embedding), dim = 0)\n",
    "                retrieved_labels = torch.cat((retrieved_labels, labels), dim = 0)\n",
    "                predicted_labels = torch.cat((predicted_labels, predictions), dim = 0)\n",
    "                ## check if maximum fetched data is reached\n",
    "            if ((retrieved_embeddings != None) and (retrieved_embeddings.size()[0] > max_retrieved)):\n",
    "                break\n",
    "    sentences = np.array(sentences)\n",
    "    X_sentences = torch.matmul(retrieved_embeddings, retrieved_embeddings.T)\n",
    "    U,S, V = torch.svd_lowrank(retrieved_embeddings)    \n",
    "    proj = torch.matmul(X_sentences, U[:, :3]).detach().numpy()\n",
    "\n",
    "    fig = go.Figure()\n",
    "   #  fig = make_subplots(rows=1,cols=2,start_cell=\"top-left\",\n",
    "   #                      specs=[\n",
    "   #      [{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}] \n",
    "   #      ]\n",
    "   # )\n",
    "    colours = ['#00FF00', '#000000', '#FF0000']    \n",
    "    # colours = ['Green', 'Black', 'Red']\n",
    "    for category, value in label2id.items():        \n",
    "        categorical_data = proj[retrieved_labels==value]\n",
    "        seived_sentences = sentences[retrieved_labels==value]\n",
    "\n",
    "        predict_categorical_data = proj[predicted_labels==value]\n",
    "        predict_seived_sentences = sentences[predicted_labels==value]\n",
    "\n",
    "        wrong_indices = (retrieved_labels==value).bitwise_and(retrieved_labels !=predicted_labels)        \n",
    "        wrong_categorical_data = proj[wrong_indices]\n",
    "        wrong_seived_sentences = sentences[wrong_indices]\n",
    "        wrong_seived_labels = predicted_labels[wrong_indices]\n",
    "\n",
    "        predicted_colours = [colours[colour_index] for colour_index in wrong_seived_labels]\n",
    "        inner_colour = [ colours[inCol] for inCol in  retrieved_labels[wrong_indices]]\n",
    "        \n",
    "        #Ground labeled \n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x= categorical_data[:, 0], y =categorical_data[:, 1], z = categorical_data[:, 2], \n",
    "            mode = 'markers',\n",
    "            name = \"True_\"+category,\n",
    "            text = seived_sentences,\n",
    "            marker=dict(\n",
    "            # size=12, # Size\n",
    "            color=colours[value], # Color            \n",
    "            opacity=0.8, # Point transparency \n",
    "            line=dict(width=1, color=colours[value]) # Properties of the edges\n",
    "            )))\n",
    "\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "                    x= wrong_categorical_data[:, 0], y =wrong_categorical_data[:, 1], z = wrong_categorical_data[:, 2], \n",
    "                    mode = 'markers',\n",
    "                    name = \"False_\"+category,\n",
    "                    text = wrong_seived_sentences,\n",
    "                    marker=dict(\n",
    "                    # size=12, # Size\n",
    "                    color=predicted_colours, # Color\n",
    "                    symbol=\"x\",\n",
    "                    opacity=0.8, # Point transparency \n",
    "                    line=dict(width=1.5, color= inner_colour) # Properties of the edges\n",
    "                    )))\n",
    "\n",
    "\n",
    "        # #Ground labeled \n",
    "        # fig.add_trace(go.Scatter3d(\n",
    "        #     x= predict_categorical_data[:, 0], y =predict_categorical_data[:, 1], z = predict_categorical_data[:, 2], \n",
    "        #     mode = 'markers',\n",
    "        #     name = \"Predicted_\"+category,\n",
    "        #     text = predict_seived_sentences,\n",
    "        #     marker=dict(\n",
    "        #     # size=12, # Size\n",
    "        #     color=colours[value], # Color            \n",
    "        #     opacity=0.8, # Point transparency \n",
    "        #     line=dict(width=1, color='black') # Properties of the edges\n",
    "        #     )),row=1, col=2)\n",
    "\n",
    "        # #wrongly labeled \n",
    "        # fig.add_trace(go.Scatter3d(\n",
    "        #     x= wrong_categorical_data[:, 0], y =wrong_categorical_data[:, 1], z = wrong_categorical_data[:, 2], \n",
    "        #     mode = 'markers',\n",
    "        #     name = \"False_\"+category,\n",
    "        #     text = wrong_seived_sentences,\n",
    "        #     marker=dict(\n",
    "        #     # size=12, # Size,\n",
    "        #     symbol=\"x\",\n",
    "        #     color=colours[value], # Color            \n",
    "        #     opacity=0.8, # Point transparency \n",
    "        #     line=dict(width=1, color='red') # Properties of the edges\n",
    "        #     )),row=1, col=2\n",
    "        # )\n",
    "\n",
    "        # fig.add_trace(go.Scatter3d(\n",
    "        #     x= categorical_data[:, 0], y =categorical_data[:, 1], z = categorical_data[:, 2], \n",
    "        #     mode = 'markers',\n",
    "        #     name = category,\n",
    "        #     text = seived_sentences,\n",
    "        #     marker=dict(\n",
    "        #     size=12, # Size\n",
    "        #     color=colours[value], # Color            \n",
    "        #     opacity=0.8, # Point transparency \n",
    "        #     line=dict(width=1, color='black') # Properties of the edges\n",
    "        #     ),\n",
    "        # ))\n",
    "\n",
    "    \n",
    "    # Customize the layout\n",
    "    fig.update_layout(\n",
    "        title='PCA', # Title\n",
    "        scene=dict(\n",
    "        xaxis_title='1st Principle Axis',\n",
    "        yaxis_title='2nd Principle Axis',\n",
    "        zaxis_title='3rd Principle Axis',\n",
    "        ),       \n",
    "        width=1200,  # Set the width of the figure to 800 pixels\n",
    "        height=800,  # Set the height of the figure to 600 pixels\n",
    "    )\n",
    "    fig.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d93fcf-6bde-499d-a83e-ae1d67456cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
